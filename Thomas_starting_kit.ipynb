{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thomas Households consumption\n",
    "\n",
    "## Goal\n",
    "The goal is to predict the consumption of each household at the next timestamp (half an hour) using the history of all consumptions. \n",
    "\n",
    "## Data\n",
    "The data is as follow :   \n",
    "- Z is a pandas.DataFrame where each row measure the consumtpions of the 172 households for a given time (one each half an hour). The first column is the timestamp (from the 1st of November 2013 to the 30th of November 2014). \n",
    "\n",
    "## The prediction task\n",
    "We split the data in N_CV=3 CV. In each CV, there are BATCH_SIZE=600 instances.\n",
    "For each instance, you are given all previous records so far. Your output is one row, the predicted next one. (Contrary to El Nino, there is no look_ahead.)\n",
    "\n",
    "The metrics is RMSE across time and households"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17847, 173)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "\n",
    "Z = pd.read_excel(\"linky.xlsx\")\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first colomns in the pandas DataFrame correspond to the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_client</th>\n",
       "      <th>1172</th>\n",
       "      <th>1272</th>\n",
       "      <th>925</th>\n",
       "      <th>2185</th>\n",
       "      <th>1280</th>\n",
       "      <th>396</th>\n",
       "      <th>404</th>\n",
       "      <th>433</th>\n",
       "      <th>638</th>\n",
       "      <th>...</th>\n",
       "      <th>2167</th>\n",
       "      <th>2232</th>\n",
       "      <th>2233</th>\n",
       "      <th>2238</th>\n",
       "      <th>2248</th>\n",
       "      <th>2257</th>\n",
       "      <th>2274</th>\n",
       "      <th>2308</th>\n",
       "      <th>2413</th>\n",
       "      <th>2482</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081256</td>\n",
       "      <td>1.230105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.635901</td>\n",
       "      <td>2.267873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.233118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205134</td>\n",
       "      <td>1.367643</td>\n",
       "      <td>1.432094</td>\n",
       "      <td>2.405136</td>\n",
       "      <td>3.234911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-01 00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964631</td>\n",
       "      <td>2.186107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.642752</td>\n",
       "      <td>1.999912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.910187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307133</td>\n",
       "      <td>0.784949</td>\n",
       "      <td>0.785386</td>\n",
       "      <td>2.039209</td>\n",
       "      <td>0.728714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300206</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750522</td>\n",
       "      <td>1.204720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.613062</td>\n",
       "      <td>2.021422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283008</td>\n",
       "      <td>0.490199</td>\n",
       "      <td>0.602877</td>\n",
       "      <td>3.305715</td>\n",
       "      <td>0.475029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318054</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-01 01:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781637</td>\n",
       "      <td>1.271173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489971</td>\n",
       "      <td>2.056820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452652</td>\n",
       "      <td>0.354070</td>\n",
       "      <td>0.333890</td>\n",
       "      <td>1.832266</td>\n",
       "      <td>2.021647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281514</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.853887</td>\n",
       "      <td>1.935372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178153</td>\n",
       "      <td>2.762370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541110</td>\n",
       "      <td>0.262270</td>\n",
       "      <td>0.266219</td>\n",
       "      <td>1.609474</td>\n",
       "      <td>0.693087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id_client  1172      1272       925  2185      1280       396  \\\n",
       "0 2013-11-01 00:00:00   0.0  1.081256  1.230105   0.0  2.635901  2.267873   \n",
       "1 2013-11-01 00:30:00   0.0  0.964631  2.186107   0.0  2.642752  1.999912   \n",
       "2 2013-11-01 01:00:00   0.0  0.750522  1.204720   0.0  2.613062  2.021422   \n",
       "3 2013-11-01 01:30:00   0.0  0.781637  1.271173   0.0  0.489971  2.056820   \n",
       "4 2013-11-01 02:00:00   0.0  0.853887  1.935372   0.0  0.178153  2.762370   \n",
       "\n",
       "   404       433  638  ...  2167      2232      2233      2238      2248  \\\n",
       "0  0.0  3.233118  0.0  ...   0.0  0.205134  1.367643  1.432094  2.405136   \n",
       "1  0.0  2.910187  0.0  ...   0.0  0.307133  0.784949  0.785386  2.039209   \n",
       "2  0.0  0.945323  0.0  ...   0.0  0.283008  0.490199  0.602877  3.305715   \n",
       "3  0.0  0.272480  0.0  ...   0.0  1.452652  0.354070  0.333890  1.832266   \n",
       "4  0.0  0.197846  0.0  ...   0.0  0.541110  0.262270  0.266219  1.609474   \n",
       "\n",
       "       2257  2274  2308      2413  2482  \n",
       "0  3.234911   0.0   0.0  0.320199   0.0  \n",
       "1  0.728714   0.0   0.0  0.300206   0.0  \n",
       "2  0.475029   0.0   0.0  0.318054   0.0  \n",
       "3  2.021647   0.0   0.0  0.281514   0.0  \n",
       "4  0.693087   0.0   0.0  0.218319   0.0  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First timestamp:\n",
      "2013-11-01 00:00:00\n",
      "Last timestamp:\n",
      "2014-11-30 23:30:00\n"
     ]
    }
   ],
   "source": [
    "print('First timestamp:')\n",
    "print(Z['Id_client'].iloc[0])\n",
    "print('Last timestamp:')\n",
    "print(Z['Id_client'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 16,  40,  74,  88, 110, 146, 161]),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are few columns with NaN\n",
    "np.where(Z.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cross-validation object\n",
    "\n",
    "For each CV, we choose BATCH_SIZE random time t.\n",
    "for each time t, Z is the raw data from time 0 to time t.\n",
    "We measure the RMSE on the prediction of the next timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pipeline\n",
    "\n",
    "Same as El Nino, predictor is a composition $f(Z_t) = h(g(Z_t))$, a feature extractor and a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The feature extractor\n",
    "\n",
    "The feature extractor implements a single `transform` function. \n",
    "It receives a DataFrame from time 0 time to a arbitrary time t, and should return a vector of features of fixed size (which will be used by the predictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/starting_kit/ts_feature_extractor.py\n"
     ]
    }
   ],
   "source": [
    "%%file submissions/starting_kit/ts_feature_extractor.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FeatureExtractor(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, Z):\n",
    "        \"\"\"Compute the running average of the last 10 days at the same time\n",
    "        \n",
    "        Z is the raw pd.DataFrame\n",
    "        return x_vector of size 172 (which will be our final prediction here)\n",
    "        \"\"\"\n",
    "        \n",
    "        Z = Z.fillna(0).drop(columns = 'Id_client')\n",
    "        \n",
    "        nb_days = int(Z.shape[0] / 48)\n",
    "        previous_measure= [-47] + [-47 - i*48 for i in range(1, min([nb_days,10]))]\n",
    "        \n",
    "        X_array = Z.iloc[previous_measure].values\n",
    "        x_vector = np.mean(X_array, axis = 0)\n",
    "    \n",
    "        return x_vector    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The regressor\n",
    "\n",
    "The regressor should implement a scikit-klearn-like regressor with fit and predict functions.  \n",
    "The starting kit uses the identity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/starting_kit/regressor.py\n"
     ]
    }
   ],
   "source": [
    "%%file submissions/starting_kit/regressor.py\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import linear_model\n",
    "\n",
    "class Regressor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass #self.reg = linear_model.BayesianRidge()\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        pass #self.reg.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = X\n",
    "        return y_pred #self.reg.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Thomas Households Consumptions\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining ./submissions/starting_kit ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.885\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.876\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.522\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.866\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.881\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.522\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.884\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.872\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.522\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore            rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.878\u001b[0m \u001b[38;5;150m±\u001b[0m \u001b[38;5;150m0.0088\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.876\u001b[0m \u001b[38;5;105m±\u001b[0m \u001b[38;5;105m0.0036\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m      \u001b[38;5;1m\u001b[1m1.522\u001b[0m \u001b[38;5;218m±\u001b[0m \u001b[38;5;218m0.0\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.876\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.522\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not understand why the test error is twice the train or valid error (since there is no fitting, there should be no overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Thomas Households Consumptions\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining ./submissions/last_point_prediction ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.654\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.651\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.471\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 1\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.652\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.656\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.471\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 2\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.664\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.652\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.471\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mMean CV scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore            rmse\u001b[0m\n",
      "\t\u001b[38;5;10m\u001b[1mtrain\u001b[0m  \u001b[38;5;10m\u001b[1m0.657\u001b[0m \u001b[38;5;150m±\u001b[0m \u001b[38;5;150m0.0051\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.653\u001b[0m \u001b[38;5;105m±\u001b[0m \u001b[38;5;105m0.0021\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m      \u001b[38;5;1m\u001b[1m1.471\u001b[0m \u001b[38;5;218m±\u001b[0m \u001b[38;5;218m0.0\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mBagged scores\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1m----------------------------\u001b[0m\n",
      "\t\u001b[38;5;178m\u001b[1mscore   rmse\u001b[0m\n",
      "\t\u001b[38;5;12m\u001b[1mvalid\u001b[0m  \u001b[38;5;12m\u001b[1m0.655\u001b[0m\n",
      "\t\u001b[38;5;1m\u001b[1mtest\u001b[0m   \u001b[38;5;1m\u001b[1m1.471\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Other model, using only the last consumption to predict the next one.\n",
    "!ramp_test_submission --submission last_point_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that predicting the next timestamp from the previous one is more accurate than using an runing average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this starting kit, we only use each single column (household) to predict itself. We could have used the entire dataset to improves our prediction, e.g. using any delayed correlation among columns or using a more sophisticated feature extraction from timestamp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
